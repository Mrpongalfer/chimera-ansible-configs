# File: /home/pong/Projects/chimera-ansible-configs/site.yml
# Version: 1.9.1 - Integrated WizardPro Bootstrap

---
- name: Pre-flight APT Cleanup and Validation on Server(s)
  hosts: server # Target only the server for cleanup specific to it
  become: yes
  gather_facts: no
  tasks:
    # --- LazyGit PPA Cleanup ---
    - name: Attempt removal of problematic lazygit PPA via module
      ansible.builtin.apt_repository:
        repo: "ppa:lazygit-team/release"
        state: absent
      ignore_errors: yes

    - name: Force removal of lazygit PPA sources list file (.list format)
      ansible.builtin.file:
        path: "/etc/apt/sources.list.d/lazygit-team-ubuntu-release-{{ ansible_distribution_release | default('noble') }}.list"
        state: absent
      ignore_errors: yes

    - name: Force removal of lazygit PPA sources file (.sources format)
      ansible.builtin.file:
        path: "/etc/apt/sources.list.d/lazygit-team-ubuntu-release-{{ ansible_distribution_release | default('noble') }}.sources"
        state: absent
      ignore_errors: yes

    # --- Docker APT Config Cleanup ---
    - name: Remove potential conflicting Docker sources file (.list)
      ansible.builtin.file:
        path: "/etc/apt/sources.list.d/docker.list"
        state: absent
      ignore_errors: yes

    - name: Remove potential conflicting Docker sources file (.sources)
      ansible.builtin.file:
        path: "/etc/apt/sources.list.d/docker.sources"
        state: absent
      ignore_errors: yes

    - name: Remove potential conflicting Docker keyring file (.gpg)
      ansible.builtin.file:
        path: "/etc/apt/keyrings/docker.gpg"
        state: absent
      ignore_errors: yes

    - name: Remove potential conflicting Docker keyring file (.asc)
      ansible.builtin.file:
        path: "/etc/apt/keyrings/docker.asc"
        state: absent
      ignore_errors: yes
    # --- End Docker Cleanup ---

    - name: Clean APT package cache thoroughly
      ansible.builtin.command: apt-get clean -y
      changed_when: false
      tags: always # Ensure clean runs even if skipping other tags

    - name: Update APT cache explicitly AFTER cleanup to validate
      ansible.builtin.apt:
        update_cache: yes
      register: preflight_apt_update_result
      retries: 1
      delay: 3
      until: preflight_apt_update_result is succeeded
      tags: always # Ensure update runs

# --- Main Configuration Play ---
- name: Apply common configuration to all hosts
  hosts: all
  become: yes
  gather_facts: yes
  vars:
    # Common Vars
    system_timezone: "America/Denver"
    admin_users:
      - { username: aiseed, shell: /bin/bash }
      - { username: pong, shell: /bin/bash }
    # Common packages defined here
    common_pkgs:
      - build-essential
      - python3-dev
      - curl
      - wget
      - git
      - vim
      - tmux
      - htop
      - net-tools
      - dnsutils
      - unzip
      - ca-certificates
      - gnupg
      - python3-pip
      - python3-venv
      - chrony
    # Security Vars
    security_ssh_port: 22
    security_fail2ban_enabled: false # Keep false if handled separately or not needed
    fail2ban_ignoreip: "127.0.0.1/8 ::1 192.168.0.0/24"
    monitoring_allowed_sources: "192.168.0.0/24"
    # Define Ports
    prometheus_port: 9091
    loki_port: 3100
    grafana_port: 3000
    node_exporter_port: 9100
    # Define UFW rules - applied via security role using these vars
    server_ufw_allow_rules:
      - {
          comment: "Allow SSH from Client",
          port: "{{ security_ssh_port }}",
          proto: tcp,
          rule: allow,
          src: "192.168.0.96",
        }
      - {
          comment: "Allow SSH from Localhost",
          port: "{{ security_ssh_port }}",
          proto: tcp,
          rule: allow,
          src: "127.0.0.1",
        }
      - {
          comment: "Allow Prometheus from Monitoring Subnet",
          port: "{{ prometheus_port }}",
          proto: tcp,
          rule: allow,
          src: "{{ monitoring_allowed_sources }}",
        }
      - {
          comment: "Allow Loki from Monitoring Subnet",
          port: "{{ loki_port }}",
          proto: tcp,
          rule: allow,
          src: "{{ monitoring_allowed_sources }}",
        }
      - {
          comment: "Allow Grafana from Monitoring Subnet",
          port: "{{ grafana_port }}",
          proto: tcp,
          rule: allow,
          src: "{{ monitoring_allowed_sources }}",
        }
      - {
          comment: "Allow Node Exporter from Monitoring Subnet",
          port: "{{ node_exporter_port }}",
          proto: tcp,
          rule: allow,
          src: "{{ monitoring_allowed_sources }}",
        } # Added Node Exporter Rule for Server
    client_ufw_allow_rules:
      - {
          comment: "Allow SSH from Server",
          port: "{{ security_ssh_port }}",
          proto: tcp,
          rule: allow,
          src: "192.168.0.95",
        }
      - {
          comment: "Allow SSH from Localhost",
          port: "{{ security_ssh_port }}",
          proto: tcp,
          rule: allow,
          src: "127.0.0.1",
        }
      - {
          comment: "Allow Node Exporter from Monitoring Subnet",
          port: "{{ node_exporter_port }}",
          proto: tcp,
          rule: allow,
          src: "{{ monitoring_allowed_sources }}",
        } # Added Node Exporter Rule for Client
    # Docker Vars
    docker_users_to_group:
      - aiseed
      - pong
    # Promtail Vars
    loki_server_url: "http://192.168.0.95:{{ loki_port }}/loki/api/v1/push"

  roles:
    - common
    - security
    - docker
    - node_exporter
    - promtail

# --- Server-Specific Configuration ---
- name: Configure server-specific settings (Monitoring Stack & WizardPro Bootstrap)
  hosts: server # Target only the server host(s) defined in inventory
  become: yes
  gather_facts: no # Facts gathered in 'all' play
  vars:
    # Define variables needed specifically by roles running only on the server
    # Values can be copied from 'all' play vars if needed, or defined uniquely here
    prometheus_port: "{{ hostvars[inventory_hostname].prometheus_port | default(9091) }}" # Inherit from all play if possible
    loki_port: "{{ hostvars[inventory_hostname].loki_port | default(3100) }}"
    grafana_port: "{{ hostvars[inventory_hostname].grafana_port | default(3000) }}"
    docker_run_user: "aiseed" # Specific user for these containers
    docker_run_group: "aiseed"
    # Prometheus Vars
    prometheus_base_dir: "/opt/docker/prometheus"
    prometheus_config_dir: "{{ prometheus_base_dir }}/config"
    prometheus_data_dir: "{{ prometheus_base_dir }}/data"
    prometheus_compose_dir: "{{ prometheus_base_dir }}"
    prometheus_template_name: "docker-compose.yml.j2"
    prometheus_compose_file_path: "{{ prometheus_compose_dir }}/docker-compose.yml"
    prometheus_config_template: "prometheus.yml.j2"
    prometheus_config_file_path: "{{ prometheus_config_dir }}/prometheus.yml"
    # Loki Vars
    loki_base_dir: "/opt/docker/loki"
    loki_config_dir: "{{ loki_base_dir }}/config"
    loki_data_dir: "{{ loki_base_dir }}/data" # Data volume managed by Docker now likely
    loki_compose_dir: "{{ loki_base_dir }}"
    loki_compose_file_path: "{{ loki_compose_dir }}/docker-compose.yml"
    loki_config_template: "loki-config.yml.j2"
    loki_config_file_path: "{{ loki_config_dir }}/loki-config.yml"
    # Grafana Vars
    grafana_base_dir: "/opt/docker/grafana"
    grafana_data_dir: "{{ grafana_base_dir }}/data" # Docker volume is likely better
    grafana_compose_dir: "{{ grafana_base_dir }}"
    grafana_compose_file_path: "{{ grafana_compose_dir }}/docker-compose.yml"
    grafana_admin_password: "{{ vault_grafana_admin_password | default('CHANGEME_PLZ') }}" # Use default or vault

  roles:
    - role: prometheus
      tags: monitoring
    - role: loki
      tags: monitoring
    - role: grafana
      tags: monitoring
    # --- ADD WIZARDPRO BOOTSTRAP ROLE HERE ---
    - role: wizardpro_bootstrap
      tags: wizardpro

# --- Client-Specific Configuration ---
- name: Configure client-specific settings
  hosts: clients # Target only the client host(s)
  become: yes
  gather_facts: no
  vars:
    placeholder_client_var: true # Example if client needs specific vars
  roles:
    # Add any client-specific roles here if needed later
    # - role: some_client_role
    - role: prompt_debug # Keeping placeholder from user provided file for now

# --- Removed duplicate play definition that was here ---
